// lib/call/services/video_call_service.dart

import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart' as webrtc;
import 'package:get/get.dart';
import 'package:socket_io_client/socket_io_client.dart' as IO;
import 'package:just_audio/just_audio.dart';
import '../../utils/api_constants.dart';
import '../../utils/auth_storage.dart';
import '../../chat/services/notification_service.dart';
import '../view/video_calling_screen.dart';
import 'call_notification_service.dart';

class VideoCallService extends GetxService {
  static VideoCallService get to => Get.find();

  // Socket connection
  IO.Socket? videoSocket;

  // WebRTC
  webrtc.RTCPeerConnection? peerConnection;

  // Make streams reactive with Rx
  final Rx<webrtc.MediaStream?> localStream = Rx<webrtc.MediaStream?>(null);
  final Rx<webrtc.MediaStream?> remoteStream = Rx<webrtc.MediaStream?>(null);

  final List<webrtc.RTCIceCandidate> _pendingCandidates = [];

  // Configuration with STUN and TURN servers for better connectivity
  // Configuration with Enhanced STUN and TURN servers for better connectivity
  final Map<String, dynamic> configuration = {
    'iceServers': [
      // Google STUN servers (Primary - High Availability)
      {'urls': 'stun:stun.l.google.com:19302'},
      {'urls': 'stun:stun1.l.google.com:19302'},
      {'urls': 'stun:stun2.l.google.com:19302'},
      {'urls': 'stun:stun3.l.google.com:19302'},
      {'urls': 'stun:stun4.l.google.com:19302'},
    ],
    'iceCandidatePoolSize': 10,
    'sdpSemantics': 'unified-plan', // Use modern WebRTC standard
    'iceTransportPolicy': 'all', // Allow both direct P2P and TURN relay
    'bundlePolicy': 'max-bundle', // Bundle audio/video on same connection
    'rtcpMuxPolicy': 'require', // Multiplex RTP and RTCP on same port
  };

  // State management
  final RxString callState = 'idle'.obs;
  final Rx<String?> currentCallerId = Rx<String?>(null);
  final Rx<String?> currentCalleeId = Rx<String?>(null);
  final Rx<String?> currentCallerUserId = Rx<String?>(null);
  final Rx<String?> currentCalleeUserId = Rx<String?>(null);

  // Connection retry management
  int _connectionRetryCount = 0;
  static const int _maxRetryAttempts = 3;
  bool _isReconnecting = false; // Track lifecycle-driven reconnections
  final RxList<String> onlineUsers = <String>[].obs;
  final RxBool isMuted = false.obs;
  final RxBool isVideoEnabled = true.obs;
  final RxBool isSpeakerOn = false.obs;
  final RxString callType = 'video'.obs;

  // Prefixed logger for video diagnostics
  void _v(String msg) {
    debugPrint('[Track video] ' + msg);
  }

  // Ringtone player
  final AudioPlayer _ringtonePlayer = AudioPlayer();

  /// Initialize the service
  Future<VideoCallService> init() async {
    await initVideoSocket();
    await _initRingtone();
    return this;
  }

// Ensure media directions are sendrecv where we have local tracks.
  String _ensureSendRecv(String sdp,
      {bool forceVideo = true, bool forceAudio = true}) {
    try {
      final lines = sdp.split('\r\n');
      String? current;
      for (int i = 0; i < lines.length; i++) {
        final l = lines[i];
        if (l.startsWith('m=video '))
          current = 'video';
        else if (l.startsWith('m=audio ')) current = 'audio';

        if (l == 'a=recvonly' || l == 'a=sendonly') {
          if ((current == 'video' && forceVideo) ||
              (current == 'audio' && forceAudio)) {
            lines[i] = 'a=sendrecv';
          }
        } else if (l == 'a=inactive') {
          if ((current == 'video' && forceVideo) ||
              (current == 'audio' && forceAudio)) {
            lines[i] = 'a=sendrecv';
          }
        }
      }
      return lines.join('\r\n');
    } catch (e) {
      debugPrint('âš ï¸ _ensureSendRecv failed: $e');
      return sdp;
    }
  }

  /// Initialize ringtone
  Future<void> _initRingtone() async {
    try {
      await _ringtonePlayer.setLoopMode(LoopMode.one);
      debugPrint('âœ… Video ringtone initialized');
    } catch (e) {
      debugPrint('âŒ Error initializing video ringtone: $e');
    }
  }

  /// Play outgoing ringback tone (non-blocking)
  Future<void> _playRingback() async {
    try {
      _ringtonePlayer.setAsset('assets/sounds/ringback.mp3').then((_) {
        return _ringtonePlayer.play();
      }).catchError((e) {
        debugPrint('âš ï¸ Could not play video ringback: $e');
      });
      debugPrint('ğŸ”” Video ringback started...');
    } catch (e) {
      debugPrint('âš ï¸ Error initiating ringback: $e');
    }
  }

  /// Play incoming ringtone (non-blocking)
  Future<void> _playIncomingRingtone() async {
    try {
      _ringtonePlayer.setAsset('assets/sounds/ringtone.mp3').then((_) {
        return _ringtonePlayer.play();
      }).catchError((e) {
        debugPrint('âš ï¸ Could not play video incoming ringtone: $e');
      });
      debugPrint('ğŸ”” Video incoming ringtone started...');
    } catch (e) {
      debugPrint('âš ï¸ Error initiating incoming ringtone: $e');
    }
  }

  /// Stop ringtone
  Future<void> _stopRingtone() async {
    try {
      await _ringtonePlayer.stop();
      debugPrint('ğŸ”• Video ringtone stopped');
    } catch (e) {
      debugPrint('âš ï¸ Error stopping video ringtone: $e');
    }
  }

  /// Initialize video socket connection
  Future<void> initVideoSocket() async {
    try {
      final userId = await AuthStorage.getBestUserIdentifier() ?? '';
      if (userId.isEmpty) {
        _v('âŒ Cannot init video socket: userId is empty');
        return;
      }

      _v('ğŸ”§ Initializing Video Socket for userId: $userId');

      // Check if we're reconnecting during an active call
      final isActiveCall = callState.value == 'calling' ||
          callState.value == 'connected' ||
          callState.value == 'incoming';

      if (isActiveCall) {
        _v('ğŸ”„ Reconnecting socket during active call - preserving call state');
        _isReconnecting = true;
      }

      // Disconnect old socket gracefully if it exists
      if (videoSocket != null) {
        _v('ğŸ”„ Disconnecting old socket...');
        videoSocket?.dispose();
        videoSocket = null;

        // Wait a moment for cleanup
        await Future.delayed(const Duration(milliseconds: 100));
      }

      // Parse URI to ensure clean URL (no :0 port for ngrok)
      final uri = Uri.parse(ApiConstants.baseUrl);
      String cleanUrl;
      if (uri.hasPort && uri.port != 80 && uri.port != 443) {
        cleanUrl = '${uri.scheme}://${uri.host}:${uri.port}';
      } else {
        cleanUrl = '${uri.scheme}://${uri.host}';
      }
      _v('ğŸ”§ Video Socket Clean URL: $cleanUrl');

      // âœ… 1) Normalize user ID (Step 1 of checklist)
      final normalizedUserId = _normalizeId(userId);

      videoSocket = IO.io(
        cleanUrl,
        IO.OptionBuilder()
            .setPath('/video-socket')
            .setTransports(['websocket', 'polling'])
            .enableReconnection()
            .setReconnectionAttempts(30)
            .setReconnectionDelay(2000)
            .setTimeout(20000)
            .disableAutoConnect()
            .enableForceNewConnection()
            .setExtraHeaders({
              'Accept': 'application/json',
              'userId': normalizedUserId, // Send normalized ID in headers too
              'ngrok-skip-browser-warning': 'true',
              'User-Agent': 'FlutterApp',
            })
            .build(),
      );

      _setupSocketListeners(normalizedUserId);
      videoSocket?.connect();

      // Reset reconnection flag after successful connection
      if (_isReconnecting) {
        _v('ğŸ”„ Waiting for socket to connect...');
        await Future.delayed(const Duration(milliseconds: 500));
        _isReconnecting = false;
        _v('âœ… Socket reconnected - call state preserved');
      }

      _v('âœ… Video socket initialized for: $normalizedUserId');
    } catch (e) {
      _v('âŒ Error initializing video socket: $e');
      _isReconnecting = false; // Reset flag on error
    }
  }

  // âœ… Helper to normalize IDs (Backend Step 1)
  String _normalizeId(String id) {
    // If it looks like a Mongo ID (24 hex chars), return as is
    final mongoIdRegExp = RegExp(r'^[0-9a-fA-F]{24}$');
    if (mongoIdRegExp.hasMatch(id)) {
      return id;
    }

    // If it's a phone number
    // Strip all non-digits first (except +)
    // If starts with 03, replace with +923
    // If already starts with +92, keep it
    if (id.startsWith('03') && id.length == 11) {
      return '+92${id.substring(1)}';
    }

    // If it's just numbers but no 03 prefix but looks like Pakistani number
    // This is user-specific logic, but complying with '03xxxxxxxxx -> +92xxxxxxxxxx' rule
    return id;
  }

  /// Setup all socket event listeners
  void _setupSocketListeners(String userId) {
    if (videoSocket == null) return;

    videoSocket!.onConnect((_) {
      _v('âœ… Video socket connected, joining with userId: $userId');
      // âœ… 2) Connect socket and join (Backend Step 2)
      // Backend expects: videoSocket.emit('join', userId);
      // Previous code sent: {'userId': userId} - FIXED
      videoSocket!.emit('join', userId);
    });

    // âœ… Listen for DYNAMIC ICE CONFIGURATION from Backend
    // This allows the server to send updated TURN credentials without app updates
    videoSocket!.on('ice_config', (data) {
      _v('ğŸ” Received Secure ICE Configuration from Server');
      _v('ğŸ“ Raw config data: $data');

      if (data is List) {
        // Convert the dynamic list to List<Map<String, dynamic>>
        final List<Map<String, dynamic>> newIceServers = [];

        // 1. Always add Google STUN servers (Base layer - High Availability)
        newIceServers.add({'urls': 'stun:stun.l.google.com:19302'});
        newIceServers.add({'urls': 'stun:stun1.l.google.com:19302'});
        newIceServers.add({'urls': 'stun:stun2.l.google.com:19302'});
        newIceServers.add({'urls': 'stun:stun3.l.google.com:19302'});
        newIceServers.add({'urls': 'stun:stun4.l.google.com:19302'});

        // 2. Add Backend Servers (TURN/STUN)
        int backendServerCount = 0;
        for (var item in data) {
          if (item is Map) {
            newIceServers.add(Map<String, dynamic>.from(item));
            backendServerCount++;
          }
        }

        configuration['iceServers'] = newIceServers;
        _v('âœ… ICE Servers updated. Total servers: ${newIceServers.length} (Backend: $backendServerCount)');

        // Verify TURN presence
        final hasTurn =
            newIceServers.any((s) => s['urls'].toString().contains('turn:'));
        if (hasTurn) {
          _v('âœ… TURN Server detected in configuration');
        } else {
          _v('âš ï¸ WARNING: No TURN server detected in backend config! Mobile data calls may fail.');
        }

        // Log all servers for verification
        for (var s in newIceServers) {
          _v('   - Server: ${s['urls']}');
        }
      } else {
        _v('âš ï¸ Invalid ICE config format received: $data');
      }
    });

    videoSocket!.onDisconnect((_) {
      _v('ğŸ”´ Video socket disconnected');

      // Skip ending call if this is a lifecycle-driven reconnection
      if (_isReconnecting) {
        _v('ğŸ”„ Socket disconnected for reconnection - preserving call state');
        return;
      }

      // Properly end the call before setting state to ended
      if (callState.value == 'calling' || callState.value == 'connected') {
        _v('ğŸ“ Call was active, sending end_call signal...');
        final peerId = currentCalleeUserId.value ?? currentCallerUserId.value;

        if (peerId != null) {
          // Use stored user ID from current state
          final currentUserId =
              currentCallerUserId.value ?? currentCalleeUserId.value;
          if (currentUserId != null) {
            _v('ğŸ“ Emitting endCall to peer=$peerId');
            endCall(userId: currentUserId, peerId: peerId);
          }
        }
      }

      // Always stop any playing ringback/ringtone on disconnect
      _stopRingtone();

      callState.value = 'ended';
    });

    videoSocket!.onError((error) {
      _v('âŒ Video socket error: $error');
    });

    videoSocket!.onAny((event, data) {
      _v('ğŸ” [SOCKET_EVENT] $event â†’ $data');

      // CRITICAL: Check if call_accepted is coming but not being caught
      if (event == 'call_accepted') {
        _v('âš ï¸âš ï¸âš ï¸ call_accepted event detected in onAny!');
        debugPrint(
            'âš ï¸ This means the event IS coming but may not be caught by the specific listener');
      }
    });

    videoSocket!.on('online_users', (data) {
      _v('ğŸ‘¥ Online users received: $data');
      if (data is List) {
        onlineUsers.value = data.map((e) => e.toString()).toList();
        _v('ğŸ‘¥ Parsed online users: ${onlineUsers.toList()}');
      }
    });

    videoSocket!.on('calling', (data) {
      _v('ğŸ“ Video calling confirmation: $data');
      if (data != null && data is Map<String, dynamic>) {
        callState.value = 'calling';
        callType.value = data['callType'] ?? 'video';

        debugPrint('');
        _v('ğŸ“ ========================================');
        _v('ğŸ“ CALLER: Now in CALLING state');
        _v('ğŸ“ ========================================');
        _v('ğŸ“ Socket connected: ${videoSocket?.connected}');
        _v('ğŸ“ Socket ID: ${videoSocket?.id}');
        _v('ğŸ“ Waiting for callee to accept...');
        _v('ğŸ“ Will receive call_accepted event when accepted');
        debugPrint('');

        // Start ringback for outgoing video call
        _playRingback();
      }
    });

    videoSocket!.on('incoming_call', (data) async {
      _v('ğŸ“ Video incoming call received: $data');
      if (data != null && data is Map<String, dynamic>) {
        // âœ… 4) Incoming call (callee flow) - Backend Check 2
        // Backend sends: callerId (display) AND callerUserId (MongoID)
        final callerIdDisplay = data['callerId'] as String;
        final callerUserId =
            data['callerUserId'] as String; // Needs to be there
        final calleeUserId =
            data['calleeUserId'] as String?; // Backend provides this too

        final offer = data['offer'] as Map<String, dynamic>;
        final callType = data['callType'] as String? ?? 'video';
        final callerName = data['callerName'] as String? ?? callerIdDisplay;
        final callerPhone = data['callerPhone'] as String? ?? callerIdDisplay;

        currentCallerId.value = callerIdDisplay; // For UI
        callState.value = 'incoming';
        this.callType.value = callType;

        // Set user IDs early so ICE candidates can be sent during 'incoming'
        try {
          final selfId = await AuthStorage.getBestUserIdentifier();
          final normalizedSelfId = _normalizeId(selfId ?? '');

          currentCallerUserId.value = callerUserId; // Store remote MongoID
          // âœ… Prioritize calleeUserId from server if available (Quick fix 1)
          currentCalleeUserId.value = calleeUserId ?? normalizedSelfId;

          _v('ğŸ“ IDs set on incoming: callerUserId=${currentCallerUserId.value}, calleeUserId=${currentCalleeUserId.value}');
        } catch (e) {
          _v('âš ï¸ Could not set IDs on incoming: $e');
        }

        // Play incoming ringtone when incoming call is received
        await _playIncomingRingtone();

        // Show incoming call notification (WhatsApp style)
        try {
          final notificationService = Get.find<CallNotificationService>();
          await notificationService.showIncomingCallNotification(
            callerId: callerIdDisplay,
            callerName: callerName,
            callerPhone: callerPhone,
            isVideoCall: true,
          );
          _v('âœ… Video call notification shown for: $callerName');
        } catch (e) {
          _v('âŒ Error showing video call notification: $e');
        }

        await _createPeerConnection(isCaller: false);
        await peerConnection?.setRemoteDescription(
          webrtc.RTCSessionDescription(offer['sdp'], offer['type']),
        );
        _v('âœ… Remote description set for incoming call');
        await _processPendingCandidates(); // Process buffered candidates

        _showIncomingCallScreen(
          callerId: callerIdDisplay,
          callerUserId: callerUserId,
          callType: callType,
        );
      }
    });

    videoSocket!.on('call_accepted', (data) async {
      debugPrint('');
      _v('ğŸ‰ğŸ‰ğŸ‰ ========================================');
      _v('ğŸ‰ CALL_ACCEPTED EVENT RECEIVED (CALLER SIDE)');
      _v('ğŸ‰ğŸ‰ğŸ‰ ========================================');
      _v('ğŸ“ Data: $data');
      _v('ğŸ“ Current call state BEFORE: ${callState.value}');
      debugPrint('');

      if (data != null && data is Map<String, dynamic>) {
        final answer = data['answer'] as Map<String, dynamic>;
        final callType = data['callType'] as String? ?? 'video';

        _v('ğŸ“ Answer SDP received: ${answer['sdp']?.toString().substring(0, 100)}...');
        _v('ğŸ“ Answer type: ${answer['type']}');

        // Stop ringtone when call is accepted
        await _stopRingtone();
        _v('ğŸ”• Ringtone stopped');

        // End incoming call notification and show ongoing call notification
        try {
          final notificationService = Get.find<CallNotificationService>();
          await notificationService.endAllCallNotifications();
          _v('âœ… Video incoming call notification ended');
        } catch (e) {
          _v('âŒ Error ending video call notification: $e');
        }

        _v('ğŸ“ Setting remote description...');
        await peerConnection?.setRemoteDescription(
          webrtc.RTCSessionDescription(answer['sdp'], answer['type']),
        );
        _v('âœ… Remote description set successfully');
        await _processPendingCandidates(); // Process buffered candidates

        // CRITICAL: Set state to connected AFTER setting remote description
        // This ensures UI updates properly
        _v('ğŸ“ Changing call state to connected...');
        callState.value = 'connected';
        this.callType.value = callType;
        _v('âœ…âœ…âœ… Call state changed to: ${callState.value}');
        _v('âœ…âœ…âœ… CALLER SHOULD NOW SEE CONNECTED SCREEN!');

        // CRITICAL: Force immediate stream update for UI
        forceStreamUpdate();

        // CRITICAL: Verify transceivers after setting remote description
        _v('ğŸ“ Verifying transceivers after answer...');
        final transceivers = await peerConnection!.getTransceivers();
        debugPrint('ğŸ“ Total transceivers: ${transceivers.length}');

        for (var t in transceivers) {
          _v('ğŸ“ Transceiver ${t.mid}:');
          _v('   - Has sender track: ${t.sender.track != null}');
          _v('   - Has receiver track: ${t.receiver.track != null}');

          if (t.receiver.track != null) {
            final track = t.receiver.track!;
            _v('   - Receiving ${track.kind} track: ${track.id}');
            _v('   - Track enabled: ${track.enabled}');
            _v('   - Track muted: ${track.muted}');

            if (track.kind == 'video' && track.muted == true) {
              debugPrint('âš ï¸ WARNING: Remote video track is MUTED!');
              debugPrint(
                  '   This means the remote peer is not sending video frames');
            }
          }
        }

        // Additional stream update after transceiver check
        Future.delayed(const Duration(milliseconds: 300), () {
          forceStreamUpdate();
          _v('ğŸ”„ Second stream update triggered');
        });
      }
    });

    videoSocket!.on('call_rejected', (data) async {
      _v('ğŸ“ Video call rejected: $data');
      if (data != null && data is Map<String, dynamic>) {
        // Stop ringtone when call is rejected
        await _stopRingtone();

        // End call notification
        try {
          final notificationService = Get.find<CallNotificationService>();
          await notificationService.endAllCallNotifications();
          _v('âœ… Video call notification ended on rejection');
        } catch (e) {
          _v('âŒ Error ending video call notification: $e');
        }

        callState.value = 'ended';
        _resetCallState();
        Get.snackbar('Call Rejected', 'User declined your call');
      }
    });

    videoSocket!.on('call_ended', (data) async {
      _v('ğŸ“ Video call ended: $data');
      if (data != null && data is Map<String, dynamic>) {
        // Stop ringtone when call ends
        await _stopRingtone();

        // End call notification
        try {
          final notificationService = Get.find<CallNotificationService>();
          await notificationService.endAllCallNotifications();
          _v('âœ… Video call notification ended');
        } catch (e) {
          _v('âŒ Error ending video call notification: $e');
        }

        callState.value = 'ended';
        final reason = data['reason'] ?? 'ended';

        _resetCallState();

        if (reason == 'offline') {
          Get.snackbar('Call Ended', 'User went offline');
        } else if (reason == 'disconnected') {
          Get.snackbar('Call Ended', 'User disconnected');
        } else {
          Get.snackbar('Call Ended', 'Call was ended');
        }
      }
    });

    videoSocket!.on('ice_candidate', (data) async {
      _v('ğŸ“ ICE candidate received: $data');
      if (data != null && data is Map<String, dynamic>) {
        final candidateData = data['candidate'] as Map<String, dynamic>;
        final candidate = webrtc.RTCIceCandidate(
          candidateData['candidate'],
          candidateData['sdpMid'],
          candidateData['sdpMLineIndex'],
        );

        if (peerConnection != null) {
          if (await peerConnection!.getRemoteDescription() != null) {
            _v('ğŸ“ Adding ICE candidate immediately');
            await peerConnection!.addCandidate(candidate);
          } else {
            _v('â³ Buffering ICE candidate (remote description not set)');
            _pendingCandidates.add(candidate);
          }
        }
      }
    });

    videoSocket!.on('call_error', (data) async {
      _v('âŒ Video call error: $data');
      if (data != null && data is Map<String, dynamic>) {
        final error = data['error'] ?? 'Unknown error';

        // âœ… WhatsApp-style: Ignore offline errors, let call continue ringing
        if (error.toLowerCase().contains('offline') ||
            error.toLowerCase().contains('not found') ||
            error.toLowerCase().contains('unavailable')) {
          _v('âš ï¸ User appears offline, but continuing call (WhatsApp style)');
          _v('âš ï¸ Will timeout after 60 seconds if no answer');

          // Show notification but DON'T end call
          Get.snackbar(
            'Calling...',
            'Ringing... (User may be offline)',
            snackPosition: SnackPosition.TOP,
            backgroundColor: Colors.blue.shade700,
            colorText: Colors.white,
            duration: Duration(seconds: 3),
          );
          return; // Don't end the call
        }

        // For other errors, end the call
        callState.value = 'ended';

        // End call notification on error
        try {
          final notificationService = Get.find<CallNotificationService>();
          await notificationService.endAllCallNotifications();
          _v('âœ… Video call notification ended on error');
        } catch (e) {
          _v('âŒ Error ending notification on call error: $e');
        }

        _resetCallState();
        Get.snackbar('Call Error', error);
      }
    });

    videoSocket!.on('user_busy', (data) async {
      _v('ğŸ“ User busy: $data');
      callState.value = 'ended';

      // End call notification when user is busy
      try {
        final notificationService = Get.find<CallNotificationService>();
        await notificationService.endAllCallNotifications();
        _v('âœ… Video call notification ended - user busy');
      } catch (e) {
        _v('âŒ Error ending notification on user busy: $e');
      }

      _resetCallState();
      Get.snackbar('User Busy', 'User is currently busy');
    });
    videoSocket!.on('join_call_room', (data) {
      _v('ğŸ“ Joined video call room: $data');
      callState.value = 'connected';
      // Stop any ringback if still playing
      _stopRingtone();
    });

    // âœ… NEW: Handle call_no_answer event (user offline - WhatsApp style)
    videoSocket!.on('call_no_answer', (data) {
      debugPrint('ğŸ“ ========================================');
      _v('ğŸ“ VIDEO CALL NO ANSWER EVENT RECEIVED (User Offline)');
      _v('ğŸ“ Data: $data');
      debugPrint('ğŸ“ ========================================');

      if (data is Map<String, dynamic>) {
        final status = data['status'];
        final message = data['message'];

        _v('ğŸ“ Status: $status');
        _v('ğŸ“ Message: $message');

        // Show user-friendly message (WhatsApp style)
        // Don't end call - let it ring for 60 seconds
        Get.snackbar(
          'Calling...',
          message ??
              'User is currently unavailable. They will see a missed call notification.',
          snackPosition: SnackPosition.TOP,
          backgroundColor: Colors.orange.shade700,
          colorText: Colors.white,
          duration: Duration(seconds: 5),
          icon: Icon(Icons.phone_missed, color: Colors.white),
        );

        _v('ğŸ“ Continuing to ring for full 60 seconds (WhatsApp style)');
        // Keep showing "Calling..." screen - let timeout handle it
      }
    });
  }

  // Process any buffered ICE candidates
  Future<void> _processPendingCandidates() async {
    if (_pendingCandidates.isEmpty) return;

    _v('â³ Processing ${_pendingCandidates.length} buffered ICE candidates...');
    for (final candidate in _pendingCandidates) {
      await peerConnection?.addCandidate(candidate);
    }
    _pendingCandidates.clear();
    _v('âœ… Buffered ICE candidates processed');
  }

  void requestOnlineUsers() {
    debugPrint('ğŸ“ Requesting online users');
    videoSocket?.emit('request_online_users');
  }

  void forceStreamUpdate() {
    debugPrint('ğŸ”„ Forcing stream update');
    if (remoteStream.value != null) {
      final stream = remoteStream.value;
      remoteStream.value = null;
      Future.delayed(const Duration(milliseconds: 50), () {
        remoteStream.value = stream;
      });
    }
  }

  // Add method to validate stream health
  bool _isStreamValid(webrtc.MediaStream? stream) {
    if (stream == null) return false;

    try {
      // Check if stream is still active
      final tracks = stream.getTracks();
      if (tracks.isEmpty) return false;

      // Check if any track is still active
      for (var track in tracks) {
        if (track.enabled) {
          return true;
        }
      }
      return false;
    } catch (e) {
      debugPrint('âŒ Error validating stream: $e');
      return false;
    }
  }

  // Add method to recover from stream failures
  Future<void> _recoverFromStreamFailure() async {
    debugPrint('ğŸ”„ Attempting to recover from stream failure...');

    // Check if we need to recreate local stream
    if (localStream.value == null || !_isStreamValid(localStream.value)) {
      debugPrint('ğŸ”„ Recreating local stream...');
      try {
        final stream = await webrtc.navigator.mediaDevices.getUserMedia({
          'audio': true,
          'video': {
            'facingMode': 'user',
            'width': {'min': 320, 'ideal': 640, 'max': 1280},
            'height': {'min': 240, 'ideal': 480, 'max': 720},
            'frameRate': {'min': 15, 'ideal': 30, 'max': 30},
          }
        });

        // Add new stream to peer connection
        if (peerConnection != null) {
          stream.getTracks().forEach((track) {
            peerConnection!.addTrack(track, stream);
          });
        }

        localStream.value = stream;
        debugPrint('âœ… Local stream recreated successfully');
      } catch (e) {
        debugPrint('âŒ Failed to recreate local stream: $e');
        // Show user-friendly error message
        Get.snackbar(
          'Camera Error',
          'Unable to access camera. Please check permissions and try again.',
          snackPosition: SnackPosition.TOP,
          backgroundColor: Colors.red,
          colorText: Colors.white,
        );
      }
    }

    // For remote stream, we need to wait for it to be re-established
    // This usually happens automatically when the peer reconnects
    debugPrint('ğŸ”„ Waiting for remote stream to be re-established...');
  }

  // Add method to handle stream errors gracefully
  void _handleStreamError(String errorType, String errorMessage) {
    debugPrint('âŒ Stream error: $errorType - $errorMessage');

    switch (errorType) {
      case 'local_stream_null':
        debugPrint('ğŸ”„ Local stream became null - attempting recovery');
        Future.delayed(const Duration(milliseconds: 1000), () {
          if (localStream.value == null) {
            _recoverFromStreamFailure();
          }
        });
        break;
      case 'remote_stream_null':
        debugPrint('âš ï¸ Remote stream became null - this might be temporary');
        // Don't try to recover remote stream immediately
        break;
      case 'stream_disposed':
        debugPrint('âš ï¸ Stream was disposed unexpectedly');
        if (_shouldPreventStreamDisposal()) {
          debugPrint(
              'ğŸ›¡ï¸ Stream disposal was prevented - call is still active');
        }
        break;
      default:
        debugPrint('âŒ Unknown stream error: $errorType');
    }
  }

  // Add method to monitor stream health
  void _startStreamHealthMonitoring() {
    Timer.periodic(const Duration(seconds: 5), (timer) {
      if (callState.value == 'connected') {
        // Check local stream health
        if (localStream.value == null || !_isStreamValid(localStream.value)) {
          debugPrint('âš ï¸ Local stream health check failed');
          _handleStreamError('local_stream_null', 'Local stream is not valid');
        }

        // Check remote stream health
        if (remoteStream.value == null) {
          debugPrint('âš ï¸ Remote stream is null during health check');
          _handleStreamError('remote_stream_null', 'Remote stream is null');
        } else if (!_isStreamValid(remoteStream.value)) {
          debugPrint('âš ï¸ Remote stream health check failed');
          _handleStreamError(
              'remote_stream_invalid', 'Remote stream is not valid');
        }
      } else {
        // Stop monitoring if call is not active
        timer.cancel();
      }
    });
  }

  // Add method to stabilize streams
  void _stabilizeStreams() {
    debugPrint('ğŸ”§ Stabilizing streams...');

    // Ensure local stream is stable
    if (localStream.value != null) {
      final stream = localStream.value!;
      debugPrint('ğŸ”§ Local stream ID: ${stream.id}');
      debugPrint('ğŸ”§ Local stream tracks: ${stream.getTracks().length}');

      // Ensure all tracks are enabled
      for (var track in stream.getTracks()) {
        if (!track.enabled) {
          track.enabled = true;
          debugPrint('ğŸ”§ Enabled local track: ${track.id}');
        }
      }
    }

    // Ensure remote stream is stable
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;
      debugPrint('ğŸ”§ Remote stream ID: ${stream.id}');
      debugPrint('ğŸ”§ Remote stream tracks: ${stream.getTracks().length}');

      // Ensure all tracks are enabled
      for (var track in stream.getTracks()) {
        if (!track.enabled) {
          track.enabled = true;
          debugPrint('ğŸ”§ Enabled remote track: ${track.id}');
        }
      }
    }
  }

  Future<void> forceVideoTrackActivation() async {
    debugPrint('ğŸ¥ Forcing video track activation');
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;
      for (var track in stream.getVideoTracks()) {
        debugPrint('ğŸ¥ Activating video track: ${track.id}');
        debugPrint('ğŸ¥ Track kind: ${track.kind}');
        debugPrint('ğŸ¥ Track enabled before: ${track.enabled}');

        // Force track to be enabled - NO TOGGLING
        if (!track.enabled) {
          track.enabled = true;
          debugPrint('âœ… Enabled video track: ${track.id}');
        }

        debugPrint('ğŸ¥ Video track state after activation:');
        debugPrint('   Enabled: ${track.enabled}');
        debugPrint('   Kind: ${track.kind}');
      }

      // Force a stream refresh with delay to ensure renderer is ready
      Future.delayed(const Duration(milliseconds: 200), () {
        remoteStream.refresh();
      });

      // Additional delay and retry
      Future.delayed(const Duration(milliseconds: 500), () {
        if (remoteStream.value != null) {
          debugPrint('ğŸ”„ Retrying video track activation after delay');
          for (var track in remoteStream.value!.getVideoTracks()) {
            if (!track.enabled) {
              debugPrint('âš ï¸ Track was disabled, re-enabling: ${track.id}');
              track.enabled = true;
            }
          }
          remoteStream.refresh();
        }
      });
    } else {
      debugPrint('âŒ Cannot force video activation: remote stream is null');
    }
  }

  // Add method to force video frame production - simplified without toggling
  Future<void> forceVideoFrameProduction() async {
    debugPrint('ğŸ¬ Forcing video frame production (simplified)');
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;
      debugPrint('ğŸ¬ Remote stream ID: ${stream.id}');
      debugPrint('ğŸ¬ Video tracks count: ${stream.getVideoTracks().length}');

      for (var track in stream.getVideoTracks()) {
        debugPrint('ğŸ¬ Processing video track: ${track.id}');
        debugPrint('ğŸ¬ Track kind: ${track.kind}');
        debugPrint('ğŸ¬ Track enabled: ${track.enabled}');

        // Simply ensure track is enabled - NO TOGGLING
        if (!track.enabled) {
          track.enabled = true;
          debugPrint('âœ… Enabled video track: ${track.id}');
        }

        debugPrint('ğŸ¬ Video track ${track.id} ensured to be enabled');
      }

      // Force multiple stream refreshes
      for (int i = 0; i < 3; i++) {
        remoteStream.refresh();
        await Future.delayed(const Duration(milliseconds: 100));
      }

      debugPrint(
          'ğŸ¬ Stream refreshed multiple times to force frame production');
    } else {
      debugPrint('âŒ Cannot force frame production: remote stream is null');
    }
  }

  // Add method to ensure video track is enabled (no stopping/restarting)
  Future<void> restartVideoTrack() async {
    debugPrint('ğŸ”„ Ensuring video track is enabled (no restart)');
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;
      final videoTracks = stream.getVideoTracks();

      if (videoTracks.isNotEmpty) {
        final track = videoTracks.first;
        debugPrint('ğŸ”„ Checking video track: ${track.id}');
        debugPrint('ğŸ”„ Track enabled: ${track.enabled}');

        // Simply ensure it's enabled - NEVER stop the track
        if (!track.enabled) {
          track.enabled = true;
          debugPrint('âœ… Enabled video track: ${track.id}');
        }

        // Force stream refresh
        remoteStream.refresh();
        debugPrint('ğŸ”„ Stream refreshed');
      }
    }
  }

  // Method to ensure remote video track is enabled
  Future<void> forceRemoteVideoRestart() async {
    debugPrint('ğŸ”„ Ensuring remote video track is enabled');
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;

      // Get all video tracks
      final videoTracks = stream.getVideoTracks();
      debugPrint('ğŸ”„ Found ${videoTracks.length} video tracks to check');

      for (var track in videoTracks) {
        debugPrint('ğŸ”„ Checking video track: ${track.id}');
        debugPrint('ğŸ”„ Track enabled: ${track.enabled}');

        // Simply ensure it's enabled - NO TOGGLING
        if (!track.enabled) {
          track.enabled = true;
          debugPrint('âœ… Enabled video track: ${track.id}');
        }
      }

      // Force stream refresh
      remoteStream.refresh();
      debugPrint('ğŸ”„ Remote stream refreshed');
    }
  }

  // Method to check if remote peer is sending video
  void checkRemoteVideoStatus() {
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;
      debugPrint('ğŸ” Remote video status check:');
      debugPrint('   Stream ID: ${stream.id}');
      debugPrint('   Video tracks: ${stream.getVideoTracks().length}');

      for (var track in stream.getVideoTracks()) {
        debugPrint('   Track ${track.id}:');
        debugPrint('     Kind: ${track.kind}');
        debugPrint('     Enabled: ${track.enabled}');
      }
    } else {
      debugPrint('âŒ Remote stream is null - no video available');
    }
  }

  // Method to force video constraints relaxation
  Future<void> relaxVideoConstraints() async {
    debugPrint('ğŸ¥ Relaxing video constraints to force frame production');

    // This method can be called to try different video constraints
    // if the current ones are too restrictive
    debugPrint('ğŸ¥ Current video constraints might be too restrictive');
    debugPrint('ğŸ¥ Consider checking remote peer\'s camera permissions');
    debugPrint('ğŸ¥ Remote peer might need to restart their camera');
  }

  // Method to optimize video constraints for better frame production
  Future<void> optimizeVideoConstraints() async {
    debugPrint('ğŸ¥ Optimizing video constraints for better frame production');

    if (localStream.value != null) {
      final stream = localStream.value!;
      final videoTracks = stream.getVideoTracks();

      for (var track in videoTracks) {
        debugPrint('ğŸ¥ Optimizing video track: ${track.id}');

        // Try to apply optimal constraints
        try {
          // Force track to be enabled and active
          track.enabled = true;

          // Apply constraints that might help with frame production
          await track.applyConstraints({
            'width': {'ideal': 640, 'max': 1280},
            'height': {'ideal': 480, 'max': 720},
            'frameRate': {'ideal': 30, 'max': 30},
            'facingMode': 'user',
          });

          debugPrint('âœ… Video constraints optimized for track: ${track.id}');
        } catch (e) {
          debugPrint('âš ï¸ Error optimizing video constraints: $e');
        }
      }
    }
  }

  // Method to prevent track disposal
  void preventTrackDisposal() {
    debugPrint('ğŸ›¡ï¸ Preventing track disposal');
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;
      debugPrint('ğŸ›¡ï¸ Remote stream is alive: ${stream.id}');

      for (var track in stream.getVideoTracks()) {
        debugPrint('ğŸ›¡ï¸ Video track ${track.id} is enabled: ${track.enabled}');
        // Ensure track stays enabled
        if (!track.enabled) {
          track.enabled = true;
          debugPrint('ğŸ›¡ï¸ Re-enabled video track: ${track.id}');
        }
      }

      // Keep stream alive by refreshing
      remoteStream.refresh();
      debugPrint('ğŸ›¡ï¸ Stream refreshed to prevent disposal');
    }
  }

  // Method to prevent premature stream disposal
  bool _shouldPreventStreamDisposal() {
    // Don't dispose streams if call is still active
    return callState.value == 'connected' ||
        callState.value == 'calling' ||
        callState.value == 'incoming';
  }

  // Method to safely dispose streams only when appropriate
  Future<void> _safeDisposeStreams() async {
    if (_shouldPreventStreamDisposal()) {
      debugPrint('ğŸ›¡ï¸ Preventing stream disposal - call is still active');
      return;
    }

    debugPrint('ğŸ§¹ Safely disposing streams...');

    // Dispose local stream
    if (localStream.value != null) {
      try {
        final stream = localStream.value!;
        for (var track in stream.getTracks()) {
          try {
            track.stop();
          } catch (e) {
            debugPrint('âš ï¸ Error stopping track ${track.id}: $e');
          }
        }
        await stream.dispose();
        localStream.value = null;
        debugPrint('âœ… Local stream safely disposed');
      } catch (e) {
        debugPrint('âš ï¸ Error disposing local stream: $e');
      }
    }

    // Dispose remote stream
    if (remoteStream.value != null) {
      try {
        final stream = remoteStream.value!;
        for (var track in stream.getTracks()) {
          try {
            track.stop();
          } catch (e) {
            debugPrint('âš ï¸ Error stopping track ${track.id}: $e');
          }
        }
        await stream.dispose();
        remoteStream.value = null;
        debugPrint('âœ… Remote stream safely disposed');
      } catch (e) {
        debugPrint('âš ï¸ Error disposing remote stream: $e');
      }
    }
  }

  // Method to diagnose remote video issues
  void diagnoseRemoteVideoIssues() {
    debugPrint('ğŸ” Diagnosing remote video issues...');
    if (remoteStream.value != null) {
      final stream = remoteStream.value!;
      debugPrint('ğŸ” Remote stream analysis:');
      debugPrint('   Stream ID: ${stream.id}');
      debugPrint('   Video tracks: ${stream.getVideoTracks().length}');
      debugPrint('   Audio tracks: ${stream.getAudioTracks().length}');

      for (var track in stream.getVideoTracks()) {
        debugPrint('   Video track ${track.id}:');
        debugPrint('     Kind: ${track.kind}');
        debugPrint('     Enabled: ${track.enabled}');
        debugPrint('     ID: ${track.id}');
      }

      debugPrint('ğŸ” Possible issues:');
      debugPrint('   1. Remote peer camera not working');
      debugPrint('   2. Remote peer camera permissions not granted');
      debugPrint('   3. Remote peer camera being used by another app');
      debugPrint('   4. WebRTC codec negotiation failed');
      debugPrint('   5. Network issues affecting video transmission');
    } else {
      debugPrint('âŒ Remote stream is null - no video available');
    }
  }

  /// Check if running on emulator
  Future<bool> _checkIfEmulator() async {
    try {
      // Check for common emulator properties
      if (defaultTargetPlatform == TargetPlatform.android) {
        // Android emulator detection
        // Note: In production, you might want to use device_info_plus package
        // for more accurate detection
        return false; // For now, assume real device
      } else if (defaultTargetPlatform == TargetPlatform.iOS) {
        // iOS simulator detection
        return false; // For now, assume real device
      }
      return false;
    } catch (e) {
      debugPrint('Error checking if emulator: $e');
      return false;
    }
  }

  Future<void> _handleConnectionFailure() async {
    _connectionRetryCount++;
    debugPrint(
        'ğŸ“ Connection failure attempt $_connectionRetryCount/$_maxRetryAttempts');

    if (_connectionRetryCount < _maxRetryAttempts) {
      debugPrint('ğŸ“ Attempting to recreate peer connection...');
      try {
        await peerConnection?.close();
        peerConnection = null;
        await Future.delayed(const Duration(seconds: 2));
        await _createPeerConnection(isCaller: localStream.value != null);

        if (callState.value == 'calling' || callState.value == 'connected') {
          debugPrint('ğŸ“ Attempting to re-establish call connection...');
        }
      } catch (e) {
        debugPrint('âŒ Error during connection retry: $e');
        if (_connectionRetryCount >= _maxRetryAttempts) {
          debugPrint('ğŸ“ Max retry attempts reached, ending call');
          callState.value = 'ended';
        }
      }
    } else {
      debugPrint('ğŸ“ Max retry attempts reached, ending call');
      callState.value = 'ended';
    }
  }

  /// Create WebRTC peer connection
  Future<void> _createPeerConnection({bool isCaller = true}) async {
    try {
      debugPrint('ğŸ“ Creating peer connection...');
      // Only request camera/mic for caller. Callee will create local stream after accept.
      webrtc.MediaStream? stream;
      if (isCaller) {
        debugPrint('ğŸ“ Requesting camera and microphone access (caller)...');

        // Create local stream with optimized constraints for better compatibility
        // Use lower resolution for emulator compatibility
        final isEmulator = await _checkIfEmulator();

        // âœ… FIX: Force lower resolution (VGA) for everyone to ensure Emulator compatibility
        // High-res (720p/1080p) from Mobile often breaks Emulator decoding
        stream = await webrtc.navigator.mediaDevices.getUserMedia({
          'audio': {
            'echoCancellation': true,
            'noiseSuppression': true,
            'autoGainControl': true,
          },
          'video': {
            'facingMode': 'user',
            'width': {'ideal': 640, 'max': 640}, // Cap at 640x480
            'height': {'ideal': 480, 'max': 480},
            'frameRate': {'ideal': 20, 'max': 30},
          }
        });

        debugPrint('ğŸ“ Local stream created successfully');
        debugPrint(
            'ğŸ“ Local stream tracks: ${stream.getVideoTracks().length} video, ${stream.getAudioTracks().length} audio');

        // Debug and ensure local video tracks are enabled
        for (var track in stream.getVideoTracks()) {
          debugPrint('ğŸ“ Local video track:');
          debugPrint('   ID: ${track.id}');
          debugPrint('   Kind: ${track.kind}');
          debugPrint('   Label: ${track.label}');
          debugPrint('   Enabled BEFORE: ${track.enabled}');
          debugPrint('   Muted: ${track.muted}');

          // Ensure track is enabled
          track.enabled = true;

          debugPrint('   Enabled AFTER: ${track.enabled}');

          // CRITICAL: Check if track is actually producing frames
          if (track.muted == true) {
            debugPrint('   âš ï¸ WARNING: Local video track is MUTED!');
            debugPrint('   This means camera is not producing frames!');
            debugPrint('   Possible causes:');
            debugPrint('   1. Camera hardware issue');
            debugPrint('   2. Camera in use by another app');
            debugPrint('   3. Camera permission not fully granted');
          }
        }

        // Update the reactive stream
        localStream.value = stream;
        debugPrint('ğŸ“ Local stream set in reactive variable');
      } else {
        debugPrint('ğŸ“ Skipping local getUserMedia for callee until accept');
      }

      // Create peer connection
      debugPrint('ğŸ“ Creating peer connection...');

      // LOG ACTIVE CONFIGURATION
      debugPrint('ğŸ“ Active ICE Configuration:');
      if (configuration['iceServers'] is List) {
        for (var server in configuration['iceServers']) {
          debugPrint('   - ${server['urls']}');
        }
      } else {
        debugPrint('âš ï¸ ICE Configuration is not a list!');
      }

      peerConnection = await webrtc.createPeerConnection(configuration);
      debugPrint('ğŸ“ Peer connection created successfully');

      // Attach local tracks via transceivers with codec preferences
      if (localStream.value != null) {
        // Attach local tracks via transceivers with codec preferences
        // ROBUST FIX: Use addTransceiver with explicit SendRecv direction
        // This ensures the SDP is correctly set to sendrecv and associates the track with the stream
        debugPrint(
            'ğŸ“ Attaching local tracks via addTransceiver (explicit SendRecv)...');

        for (final track in stream!.getTracks()) {
          try {
            await peerConnection!.addTransceiver(
              track: track,
              init: webrtc.RTCRtpTransceiverInit(
                direction: webrtc.TransceiverDirection.SendRecv,
                streams: [
                  stream
                ], // Critical for Unified Plan to associate track with stream
                // No sendEncodings - let WebRTC choose defaults to avoid "invalid dimensions"
              ),
            );
            debugPrint(
                'âœ… Added transceiver for track: ${track.id} (${track.kind})');
          } catch (e) {
            debugPrint('âš ï¸ Failed adding transceiver: $e');
          }
        }

        // Verify all transceivers after adding
        final transceivers = await peerConnection!.getTransceivers();
        debugPrint('ğŸ“ Total transceivers configured: ${transceivers.length}');
        for (var transceiver in transceivers) {
          if (transceiver.sender.track != null) {
            debugPrint(
                '   - Sending ${transceiver.sender.track!.kind} track: ${transceiver.sender.track!.id}');
          }
        }
      }
      // REMOVED: Manual RecvOnly transceivers for callee
      // WebRTC will automatically create receivers when setRemoteDescription is called with the Offer.
      // This simplifies the logic and reduces state mismatch errors.
      debugPrint(
          'ğŸ“ Waiting for Offer to establish receivers (standard WebRTC behavior)');

      // Setup onTrack handler for receiving remote tracks
      peerConnection!.onTrack = (webrtc.RTCTrackEvent event) async {
        debugPrint('ğŸ“ Remote track received: ${event.track.kind}');
        _v('ğŸ“ Track ID: ${event.track.id}');
        _v('ğŸ“ Streams in event: ${event.streams.length}');
        _v('ğŸ“ Track label: ${event.track.label}');
        _v('ğŸ“ Track enabled: ${event.track.enabled}, muted: ${event.track.muted}');
        // Try to log track settings (resolution/framerate) if supported on platform
        try {
          final dynTrack = event.track as dynamic;
          final settings = await dynTrack.getSettings();
          debugPrint('ğŸ“ Track settings: $settings');
        } catch (_) {}

        // Enable the track immediately
        event.track.enabled = true;

        // CRITICAL FIX: Handle streams properly
        if (event.streams.isNotEmpty) {
          final stream = event.streams[0];
          _v('ğŸ“ Track received WITH stream: ${stream.id}');

          // Ensure all tracks are enabled
          for (var track in stream.getTracks()) {
            track.enabled = true;
          }

          // Update the stream (triggers UI update)
          remoteStream.value = stream;
          _v('âœ… Remote stream updated: video=${stream.getVideoTracks().length}, audio=${stream.getAudioTracks().length}');
        } else {
          // Track received without an associated stream - create one manually
          _v('âš ï¸ Track received WITHOUT stream - creating MediaStream manually');
          try {
            final manual = await webrtc.createLocalMediaStream(
                'remote-stream-${DateTime.now().millisecondsSinceEpoch}');
            manual.addTrack(event.track);
            // Ensure the new track is enabled
            event.track.enabled = true;
            // Update reactive remote stream
            remoteStream.value = manual;
            _v('âœ… Manual remote stream created: video=${manual.getVideoTracks().length}, audio=${manual.getAudioTracks().length}');
          } catch (e) {
            _v('âŒ Failed to create manual remote stream: $e');
          }
        }
      };

      // Additional listener for addStream (fallback for older WebRTC implementations)
      peerConnection!.onAddStream = (webrtc.MediaStream stream) {
        _v('ğŸ“ Remote stream via onAddStream');

        for (var track in stream.getTracks()) {
          track.enabled = true;
        }

        remoteStream.value = stream;
      };

      // Listen for ICE candidates
      peerConnection!.onIceCandidate = (webrtc.RTCIceCandidate? candidate) {
        if (candidate != null && callState.value != 'ended') {
          debugPrint('ğŸ“ ICE candidate generated: ${candidate.candidate}');

          String? targetUserId;

          // Logic: Send to the OTHER party
          if (isCaller) {
            // I am the Caller -> Send to Callee
            targetUserId = currentCalleeUserId.value;
          } else {
            // I am the Callee -> Send to Caller
            targetUserId = currentCallerUserId.value;
          }

          debugPrint(
              'ğŸ“ Sending ICE candidate to peer (isCaller=$isCaller): $targetUserId');
          debugPrint(
              'ğŸ“ IDs: Caller=${currentCallerUserId.value}, Callee=${currentCalleeUserId.value}');

          if (targetUserId != null) {
            debugPrint('ğŸ“ Sending ICE candidate to user ID: $targetUserId');
            try {
              sendIceCandidate(
                toUserId: targetUserId,
                candidate: {
                  'candidate': candidate.candidate,
                  'sdpMid': candidate.sdpMid,
                  'sdpMLineIndex': candidate.sdpMLineIndex,
                },
              );
            } catch (e) {
              debugPrint('âŒ Error sending ICE candidate: $e');
            }
          } else {
            debugPrint('âŒ No target user ID for ICE candidate');
            debugPrint('âŒ Current caller ID: ${currentCallerUserId.value}');
            debugPrint('âŒ Current callee ID: ${currentCalleeUserId.value}');
          }
        }
      };

      // Listen for connection state changes
      peerConnection!.onConnectionState =
          (webrtc.RTCPeerConnectionState state) {
        _v('ğŸ“ Connection state: $state');
        if (state ==
            webrtc.RTCPeerConnectionState.RTCPeerConnectionStateConnected) {
          callState.value = 'connected';
          _v('ğŸ“ Peer connection established successfully');
          webrtc.Helper.setSpeakerphoneOn(true);

          // CRITICAL: Comprehensive diagnostics for remote tracks
          Future.delayed(const Duration(milliseconds: 1000), () {
            _v('ğŸ” ========== REMOTE TRACK DIAGNOSTICS ==========');

            // Check remote stream
            if (remoteStream.value != null) {
              final stream = remoteStream.value!;
              _v('âœ… Remote stream exists: ${stream.id}');
              _v('   - Video tracks: ${stream.getVideoTracks().length}');
              _v('   - Audio tracks: ${stream.getAudioTracks().length}');

              for (var track in stream.getVideoTracks()) {
                _v('   ğŸ“¹ Video track ${track.id}:');
                _v('      - Enabled: ${track.enabled}');
                _v('      - Muted: ${track.muted}');
                _v('      - Label: ${track.label}');
              }

              for (var track in stream.getAudioTracks()) {
                debugPrint('   ğŸ”Š Audio track ${track.id}:');
                debugPrint('      - Enabled: ${track.enabled}');
                debugPrint('      - Muted: ${track.muted}');
              }
            } else {
              debugPrint('âŒ Remote stream is NULL!');
            }

            // Check receivers
            if (peerConnection != null) {
              peerConnection!.getReceivers().then((receivers) {
                _v('ğŸ“Š Total receivers: ${receivers.length}');
                for (var receiver in receivers) {
                  if (receiver.track != null) {
                    _v('   - Receiver track: ${receiver.track!.kind}');
                    _v('     - ID: ${receiver.track!.id}');
                    _v('     - Enabled: ${receiver.track!.enabled}');
                    _v('     - Muted: ${receiver.track!.muted}');
                  } else {
                    _v('   - Receiver has NULL track!');
                  }
                }

                // Check transceivers
                peerConnection!.getTransceivers().then((transceivers) {
                  _v('ğŸ“Š Total transceivers: ${transceivers.length}');
                  for (var transceiver in transceivers) {
                    _v('   - Transceiver: ${transceiver.mid}');
                    if (transceiver.receiver.track != null) {
                      _v('     - Has track: ${transceiver.receiver.track!.kind}');
                      _v('     - Track enabled: ${transceiver.receiver.track!.enabled}');
                    }
                  }
                  _v('ğŸ” ========== END DIAGNOSTICS ==========');
                });
              });
            }

            // Check if remote stream is null
            if (remoteStream.value == null) {
              _v('âš ï¸ CRITICAL: Remote stream is NULL after connection!');
              _v('   This means onTrack event did not fire!');
            } else {
              _v('âœ… Remote stream exists: ${remoteStream.value!.id}');
            }
          });

          // Start stream health monitoring
          _startStreamHealthMonitoring();

          // Stabilize streams to prevent nullification
          _stabilizeStreams();

          // Optimize video constraints for better frame production
          Future.delayed(const Duration(milliseconds: 200), () {
            optimizeVideoConstraints();
          });

          // Ensure streams are still valid after connection
          Future.delayed(const Duration(milliseconds: 500), () {
            if (localStream.value == null) {
              debugPrint(
                  'âš ï¸ Local stream is null after connection - attempting recovery');
              _recoverFromStreamFailure();
            }
          });
        } else if (state ==
                webrtc.RTCPeerConnectionState.RTCPeerConnectionStateFailed ||
            state ==
                webrtc.RTCPeerConnectionState
                    .RTCPeerConnectionStateDisconnected) {
          _v('ğŸ“ Connection failed or disconnected, attempting to reconnect...');

          if (state ==
              webrtc.RTCPeerConnectionState.RTCPeerConnectionStateFailed) {
            _v('ğŸ“ Connection failed - attempting to recreate peer connection...');
            _handleConnectionFailure();
          } else if (state ==
              webrtc
                  .RTCPeerConnectionState.RTCPeerConnectionStateDisconnected) {
            debugPrint(
                'ğŸ“ Connection disconnected - will attempt to reconnect...');
            // Don't immediately dispose streams on disconnection
            // They might be re-established
          } else if (state ==
              webrtc.RTCPeerConnectionState.RTCPeerConnectionStateClosed) {
            debugPrint('ğŸ“ Peer connection closed - remote peer disconnected');
            // Handle abrupt disconnection
            if (callState.value == 'connected' ||
                callState.value == 'calling') {
              debugPrint('ğŸ“ Remote peer disconnected abruptly, ending call');
              callState.value = 'ended';
            }
          }
        }
      };

      // Listen for ICE connection state changes
      peerConnection!.onIceConnectionState =
          (webrtc.RTCIceConnectionState state) {
        debugPrint('ğŸ“ ICE Connection State Changed: $state');
        // Add granular logging for debugging
        if (state == webrtc.RTCIceConnectionState.RTCIceConnectionStateFailed) {
          debugPrint('âŒâŒâŒ ICE Connection FAILED');
          debugPrint('   This usually means NAT traversal failed.');
          debugPrint('   Possible causes:');
          debugPrint(
              '   1. Strict Firewall blocking UDP traffic on one or both sides.');
          debugPrint('   2. STUN servers failed to resolve public IP.');
          debugPrint(
              '   3. TURN server is required but not configured or unreachable.');
          debugPrint(
              '   4. Symmetric NAT detected (Difficult for P2P without TURN).');

          Get.snackbar(
            'Connection Failed',
            'Could not establish direct connection. Retrying...',
            backgroundColor: Colors.red,
            colorText: Colors.white,
          );
        } else if (state ==
            webrtc.RTCIceConnectionState.RTCIceConnectionStateDisconnected) {
          debugPrint(
              'âš ï¸ ICE Connection DISCONNECTED - potentially switching networks or signal loss.');
        } else if (state ==
            webrtc.RTCIceConnectionState.RTCIceConnectionStateConnected) {
          debugPrint(
              'âœ… ICE Connection ESTABLISHED - Direct P2P or Relay successful!');
        } else if (state ==
            webrtc.RTCIceConnectionState.RTCIceConnectionStateChecking) {
          debugPrint('ğŸ”„ ICE Checking - Negotiating candidates...');
        }
      };

      // Listen for signaling state changes
      peerConnection!.onSignalingState = (webrtc.RTCSignalingState state) {
        debugPrint('ğŸ“ Signaling state: $state');
      };
    } catch (e) {
      debugPrint('âŒ Error creating peer connection: $e');
      Get.snackbar('Error', 'Failed to access camera or microphone');
    }
  }

  /// Initiate video call
  Future<void> initiateVideoCall({
    required String callerId,
    required String calleeId,
    String? calleeName,
    String? calleeFcmToken, // FCM token for push notifications
  }) async {
    try {
      // âœ… Normalize IDs for backend (Step 3 of checklist)
      final normalizedCallerId = _normalizeId(callerId);
      final normalizedCalleeId = _normalizeId(calleeId);

      debugPrint(
          'ğŸ“ Initiating video call from $normalizedCallerId to $normalizedCalleeId');

      _connectionRetryCount = 0;

      debugPrint('ğŸ“ Setting user IDs for ICE candidates:');
      debugPrint('   Caller ID: $normalizedCallerId');
      debugPrint('   Callee ID: $normalizedCalleeId');

      currentCallerUserId.value = normalizedCallerId;
      currentCalleeUserId.value = normalizedCalleeId;

      debugPrint('ğŸ“ User IDs set in reactive variables:');
      debugPrint('   currentCallerUserId: ${currentCallerUserId.value}');
      debugPrint('   currentCalleeUserId: ${currentCalleeUserId.value}');
      callState.value = 'calling';
      callType.value = 'video';
      // Start outgoing video call ringtone immediately (WhatsApp style)
      await _playRingback();

      // ğŸ“² Send direct FCM notification for offline users (like message notifications)
      if (calleeFcmToken != null && calleeFcmToken.isNotEmpty) {
        try {
          final callerPhone =
              await AuthStorage.getPhoneNumber() ?? normalizedCallerId;
          final callerName = calleeName ?? callerPhone;
          final notificationService = NotificationService();
          final callId = DateTime.now().millisecondsSinceEpoch.toString();
          await notificationService.sendCallNotification(
            token: calleeFcmToken,
            callerName: callerName,
            callType: 'video',
            callId: callId,
            callerId: normalizedCallerId,
          );
          debugPrint('ğŸ“² Direct FCM video call notification sent successfully');
        } catch (e) {
          debugPrint('âš ï¸ Failed to send direct FCM notification: $e');
        }
      } else {
        debugPrint(
            'âš ï¸ No FCM token available for callee, skipping notification');
      }

      await _createPeerConnection(isCaller: true);

      // CRITICAL: Ensure transceivers are properly configured before creating offer
      final transceivers = await peerConnection!.getTransceivers();
      debugPrint(
          'ğŸ“ Transceivers after _createPeerConnection: ${transceivers.length}');

      // Verify each transceiver has a sending track
      for (var t in transceivers) {
        debugPrint(
            'ğŸ“ Caller transceiver: ${t.mid}, sender: ${t.sender.track != null}, receiver: ${t.receiver.track != null}');
        if (t.sender.track != null) {
          final track = t.sender.track!;
          debugPrint('   - Sending ${track.kind} track: ${track.id}');
          debugPrint('   - Track enabled: ${track.enabled}');
          debugPrint('   - Track muted: ${track.muted}');

          // Force enable the track
          track.enabled = true;
        }
      }

      // Ensure we have both audio and video transceivers
      if (transceivers.length < 2) {
        debugPrint(
            'âš ï¸ WARNING: Only ${transceivers.length} transceivers found, expected 2');
        debugPrint('ğŸ“ This may cause remote video to not work');
      }

      debugPrint('ğŸ“ Creating offer with optimized constraints...');
      var offer = await peerConnection!.createOffer({
        'offerToReceiveAudio': true,
        'offerToReceiveVideo': true,
        'voiceActivityDetection': true,
        'iceRestart': false, // Don't restart ICE unless needed
      });
      debugPrint('ğŸ“ Offer created');

      // CRITICAL CHECK: Ensure SDP is not null
      if (offer.sdp == null || offer.sdp!.isEmpty) {
        throw Exception('Generated Offer SDP is null or empty!');
      }

      debugPrint(
          'ğŸ“ Offer SDP: ${offer.sdp?.substring(0, 200)}...'); // Log first 200 chars

      debugPrint('ğŸ“ Setting local description with codec preferences...');
      // Prefer VP8 over H264 to avoid MTK H264 encoder issues
      // Also ensure proper media direction
      // Safe SDP Munging
      webrtc.RTCSessionDescription finalOffer = offer;
      try {
        var mungedSdp = offer.sdp!;

        // Ensure sendrecv for both audio and video
        // mungedSdp =
        //    _ensureSendRecv(mungedSdp, forceVideo: true, forceAudio: true);

        // Force VP8 codec
        // mungedSdp = _preferVp8(mungedSdp);

        // Verify munging didn't break anything
        if (mungedSdp.isEmpty) {
          debugPrint(
              'âš ï¸ Munging resulted in empty SDP! Reverting to original.');
          finalOffer = offer;
        } else {
          finalOffer = webrtc.RTCSessionDescription(mungedSdp, offer.type);
        }
      } catch (e) {
        debugPrint(
            'âš ï¸ Failed to prepare offer SDP: $e. Reverting to original.');
        finalOffer = offer;
      }

      try {
        await peerConnection!.setLocalDescription(finalOffer);
        debugPrint('ğŸ“ Local description set successfully');
      } catch (e) {
        debugPrint('âŒ Failed to set local description: $e');

        // If modified failed, try original as last resort
        if (finalOffer != offer) {
          debugPrint('ğŸ”„ Retrying with original unmodified offer...');
          await peerConnection!.setLocalDescription(offer);
          finalOffer = offer;
          debugPrint('âœ… Original offer set successfully on retry');
        } else {
          rethrow;
        }
      }

      // Use the actually set description for sending via signaling
      final descriptionToSend = await peerConnection!.getLocalDescription();
      if (descriptionToSend == null) {
        throw Exception('Local description is null after setting!');
      }
      debugPrint('ğŸ“ Local description to send recovered successfully');

      final callData = {
        'callerId':
            normalizedCallerId, // MongoDB user ID - server uses this for matching
        'calleeId': normalizedCalleeId, // Use actual callee ID from parameter
        'offer': {
          'sdp': descriptionToSend.sdp,
          'type': descriptionToSend.type,
        },
        'callType': 'video'
      };

      debugPrint('ğŸ“ Requesting latest online users...');
      videoSocket?.emit('request_online_users');
      await Future.delayed(const Duration(milliseconds: 500));

      debugPrint('ğŸ“ Emitting video call_user event...');
      debugPrint('ğŸ“ Call data being sent: $callData');
      videoSocket?.emit('call_user', callData);
      debugPrint('ğŸ“ Emitted video call_user event successfully');

      _showVideoCallingScreen(
        contactName: calleeName ?? normalizedCalleeId,
        contactPhone: normalizedCalleeId,
        isIncoming: false,
      );

      // 60 second timeout like WhatsApp
      Timer(const Duration(seconds: 60), () {
        if (callState.value == 'calling') {
          debugPrint(
              'ğŸ“ Call timeout - no response from callee after 60 seconds');

          // Stop ringback before ending call
          _stopRingtone();

          callState.value = 'ended';

          // End call notification on timeout
          try {
            final notificationService = Get.find<CallNotificationService>();
            notificationService.endAllCallNotifications();
            debugPrint('âœ… Video call notification ended on timeout');
          } catch (e) {
            debugPrint('âŒ Error ending notification on timeout: $e');
          }

          _resetCallState();
          Get.snackbar('Call Ended', 'No answer');
          Get.back();
        }
      });
    } catch (e) {
      debugPrint('âŒ Error initiating video call: $e');
      callState.value = 'ended';
    }
  }

  Future<void> acceptCall({
    required String callerId,
    required String calleeId,
  }) async {
    try {
      // âœ… Normalize IDs for backend (Step 4 of checklist)
      final normalizedCallerId = _normalizeId(callerId);
      final normalizedCalleeId = _normalizeId(calleeId);

      debugPrint('ğŸ“ ============================================');
      debugPrint('ğŸ“ ACCEPTING VIDEO CALL');
      debugPrint('ğŸ“ Caller ID: $normalizedCallerId');
      debugPrint('ğŸ“ Callee ID: $normalizedCalleeId');
      debugPrint('ğŸ“ Local stream exists: ${localStream.value != null}');
      if (localStream.value != null) {
        debugPrint(
            'ğŸ“ Local video tracks: ${localStream.value!.getVideoTracks().length}');
        debugPrint(
            'ğŸ“ Local audio tracks: ${localStream.value!.getAudioTracks().length}');
      }
      debugPrint('ğŸ“ ============================================');

      // âœ… CRITICAL: Stop ringtone immediately when accepting call
      await _stopRingtone();
      debugPrint('ğŸ”• Video ringtone stopped on accept');

      // âœ… CRITICAL: Dismiss incoming call notification immediately
      try {
        final notificationService = Get.find<CallNotificationService>();
        await notificationService.endAllCallNotifications();
        debugPrint('âœ… Video incoming call notification dismissed on accept');
      } catch (e) {
        debugPrint('âŒ Error dismissing notification on accept: $e');
      }

      // CRITICAL: Set user IDs for ICE candidates to match callData
      currentCallerUserId.value = normalizedCallerId;
      currentCalleeUserId.value = normalizedCalleeId;

      debugPrint('ğŸ“ User IDs set for ICE candidates in acceptCall:');
      debugPrint('   currentCallerUserId: ${currentCallerUserId.value}');
      debugPrint('   currentCalleeUserId: ${currentCalleeUserId.value}');

      callState.value = 'connected';
      debugPrint('âœ… Callee call state changed to: connected');

      // CRITICAL: Force immediate UI update for callee
      forceStreamUpdate();

      // CRITICAL: Ensure we have transceivers and attach local tracks before creating answer
      final transceivers = await peerConnection!.getTransceivers();
      debugPrint('ğŸ“ Transceivers before answer: ${transceivers.length}');

      // Ensure callee has a local stream; if missing, create it now (after accept)
      if (localStream.value == null) {
        try {
          final isEmulator = await _checkIfEmulator();
          final newStream = await webrtc.navigator.mediaDevices.getUserMedia({
            'audio': {
              'echoCancellation': true,
              'noiseSuppression': true,
              'autoGainControl': true,
            },
            'video': isEmulator
                ? {
                    'facingMode': 'user',
                    'width': {'ideal': 640},
                    'height': {'ideal': 480},
                    'frameRate': {'ideal': 15},
                  }
                : {
                    'facingMode': 'user',
                    'width': {'min': 320, 'ideal': 640, 'max': 1280},
                    'height': {'min': 240, 'ideal': 480, 'max': 720},
                    'frameRate': {'min': 15, 'ideal': 24, 'max': 30},
                    'aspectRatio': 1.777,
                  }
          });
          // Enable tracks
          for (var t in newStream.getTracks()) {
            t.enabled = true;
          }
          localStream.value = newStream;
          debugPrint('ğŸ“ Callee local stream created on accept');
        } catch (e) {
          debugPrint('âŒ Failed to create callee local stream on accept: $e');
        }
      }

      // CRITICAL FIX: Use standard addTrack method
      if (localStream.value != null) {
        final stream = localStream.value!;
        debugPrint('ğŸ“ Adding local tracks to peer connection...');

        // Simply add tracks - WebRTC will attach them to the existing transceivers created by the Offer
        for (var track in stream.getTracks()) {
          try {
            await peerConnection!.addTrack(track, stream);
            debugPrint('âœ… Added local track: ${track.id} (${track.kind})');
          } catch (e) {
            debugPrint('âš ï¸ Error adding local track ${track.id}: $e');
          }
        }

        debugPrint('âœ… Local tracks added to peer connection');
      } else {
        debugPrint('âš ï¸ WARNING: No local stream available for callee!');
        debugPrint('ğŸ“ This will cause remote video to be 0x0');
      }

      var answer = await peerConnection!.createAnswer({
        'offerToReceiveAudio': true,
        'offerToReceiveVideo': true,
        'voiceActivityDetection': true,
      });

      // CRITICAL CHECK: Ensure SDP is not null
      if (answer.sdp == null || answer.sdp!.isEmpty) {
        throw Exception('Generated Answer SDP is null or empty!');
      }

      // CRITICAL: Check if answer has SSRC entries for video
      final originalSdp = answer.sdp ?? '';
      if (!originalSdp.contains('a=ssrc') || !originalSdp.contains('m=video')) {
        debugPrint('âš ï¸ WARNING: Answer SDP missing SSRC entries!');
        debugPrint('ğŸ“ This means local tracks are not properly attached');
      }

      // Safe SDP Munging for Answer
      webrtc.RTCSessionDescription finalAnswer = answer;
      try {
        var munged = originalSdp;
        // Always force sendrecv for both audio and video
        // munged = _ensureSendRecv(munged, forceVideo: true, forceAudio: true);

        // Force VP8 codec in Answer too
        // munged = _preferVp8(munged);

        if (munged.isEmpty) {
          debugPrint(
              'âš ï¸ Munging resulted in empty SDP! Reverting to original.');
          finalAnswer = answer;
        } else {
          finalAnswer = webrtc.RTCSessionDescription(munged, answer.type);
        }
      } catch (e) {
        debugPrint('âš ï¸ Failed to munge SDP: $e. Reverting to original.');
        finalAnswer = answer;
      }

      try {
        await peerConnection!.setLocalDescription(finalAnswer);
        debugPrint('ğŸ“ Answer local description set successfully');
      } catch (e) {
        debugPrint('âŒ Failed to set local description: $e');

        // If modified failed, try original as last resort
        if (finalAnswer != answer) {
          debugPrint('ğŸ”„ Retrying with original unmodified answer...');
          await peerConnection!.setLocalDescription(answer);
          finalAnswer = answer;
          debugPrint('âœ… Original answer set successfully on retry');
        } else {
          rethrow;
        }
      }

      // Use the actually set description for sending
      final descriptionToSend = await peerConnection!.getLocalDescription();
      if (descriptionToSend == null) {
        throw Exception('Local description is null after setting!');
      }
      debugPrint('ğŸ“ Answer created');
      debugPrint(
          'ğŸ“ Answer SDP: ${descriptionToSend.sdp?.substring(0, 200)}...');

      // Log if video SSRC is present
      if (descriptionToSend.sdp!.contains('a=ssrc') &&
          descriptionToSend.sdp!.contains('m=video')) {
        debugPrint('âœ… Answer contains SSRC entries for video');
      } else {
        debugPrint('âŒ CRITICAL: Answer missing SSRC entries for video!');
      }

      final acceptData = {
        'callerId':
            normalizedCallerId, // MongoDB user ID - server uses this for matching
        'calleeId': normalizedCalleeId, // Use actual callee ID from parameter
        'answer': {
          'sdp': descriptionToSend.sdp,
          'type': descriptionToSend.type,
        }
      };

      debugPrint('');
      debugPrint('ğŸ“¤ğŸ“¤ğŸ“¤ ========================================');
      debugPrint('ğŸ“¤ EMITTING accept_call EVENT TO SERVER');
      debugPrint('ğŸ“¤ğŸ“¤ğŸ“¤ ========================================');
      debugPrint(
          'ğŸ“¤ Caller ID (will receive call_accepted): $normalizedCallerId');
      debugPrint('ğŸ“¤ Callee ID (this device): $normalizedCalleeId');
      debugPrint('ğŸ“¤ Answer SDP length: ${answer.sdp?.length ?? 0}');
      debugPrint('ğŸ“¤ Socket connected: ${videoSocket?.connected}');
      debugPrint('ğŸ“¤ Socket ID: ${videoSocket?.id}');
      debugPrint('');

      if (videoSocket?.connected != true) {
        debugPrint('âŒâŒâŒ CRITICAL: Socket is NOT connected!');
        debugPrint('âŒ Cannot emit accept_call event!');
        debugPrint('âŒ Reconnecting socket...');
        videoSocket?.connect();
        await Future.delayed(const Duration(seconds: 2));
      }

      videoSocket?.emit('accept_call', acceptData);
      debugPrint('âœ… accept_call event emitted to server');
      debugPrint(
          'â³ Waiting for caller ($normalizedCallerId) to receive call_accepted event...');
      debugPrint('');
      debugPrint('ğŸ” If caller does NOT receive call_accepted:');
      debugPrint('   1. Check server logs for accept_call event');
      debugPrint(
          '   2. Check if server is emitting call_accepted to correct user');
      debugPrint('   3. Check caller socket connection status');
    } catch (e) {
      debugPrint('âŒ Error accepting call: $e');
    }
  }

  Future<void> rejectCall({
    required String callerId,
    required String calleeId,
  }) async {
    try {
      // âœ… Normalize IDs (Consistency)
      final normalizedCallerId = _normalizeId(callerId);
      final normalizedCalleeId = _normalizeId(calleeId);

      debugPrint('ğŸ“ Rejecting video call from $normalizedCallerId');

      // âœ… CRITICAL: Stop ringtone when rejecting call
      await _stopRingtone();
      debugPrint('ğŸ”• Video ringtone stopped on reject');

      // âœ… CRITICAL: Dismiss incoming call notification immediately
      try {
        final notificationService = Get.find<CallNotificationService>();
        await notificationService.endAllCallNotifications();
        debugPrint('âœ… Video incoming call notification dismissed on reject');
      } catch (e) {
        debugPrint('âŒ Error dismissing notification on reject: $e');
      }

      callState.value = 'ended';

      final rejectData = {
        'callerId': normalizedCallerId,
        'calleeId': normalizedCalleeId,
      };

      videoSocket?.emit('reject_call', rejectData);
      debugPrint('ğŸ“ Emitted reject_call event');

      _resetCallState();
    } catch (e) {
      debugPrint('âŒ Error rejecting call: $e');
    }
  }

  Future<void> endCall({
    required String userId,
    required String peerId,
  }) async {
    try {
      debugPrint('ğŸ“ Ending video call between $userId and $peerId');

      // CRITICAL: Stop ringtone when ending call
      await _stopRingtone();

      // âœ… 5) Normalize IDs for end_call (Backend requirement)
      // Always ensure we are sending MongoID or E.164, never raw '03...'
      final normalizedUserId = _normalizeId(userId);
      final normalizedPeerId = _normalizeId(peerId);

      callState.value = 'ended';

      final endData = {
        'userId': normalizedUserId,
        'peerId': normalizedPeerId,
      };

      debugPrint('ğŸ“ Emitting end_call event with normalized IDs: $endData');
      videoSocket?.emit('end_call', endData);
      debugPrint('ğŸ“ Emitted end_call event');

      _resetCallState();
    } catch (e) {
      debugPrint('âŒ Error ending call: $e');
    }
  }

  void sendIceCandidate({
    required String toUserId,
    required Map<String, dynamic> candidate,
  }) {
    debugPrint('ğŸ“ Sending ICE candidate to $toUserId');

    final iceCandidateData = {
      'candidate': candidate,
      'toUserId': toUserId,
    };

    if (videoSocket?.connected == true) {
      videoSocket?.emit('ice_candidate', iceCandidateData);
    } else {
      debugPrint(
          'âŒ CRITICAL: Socket disconnected! Cannot send ICE candidate to $toUserId');
    }
  }

  Future<void> toggleMute() async {
    if (localStream.value != null) {
      final audioTrack = localStream.value!.getAudioTracks().first;
      audioTrack.enabled = !audioTrack.enabled;
      isMuted.value = !audioTrack.enabled;
      debugPrint('ğŸ“ Mute toggled: ${isMuted.value}');
    }
  }

  Future<void> toggleVideo() async {
    if (localStream.value != null) {
      final videoTrack = localStream.value!.getVideoTracks().first;
      videoTrack.enabled = !videoTrack.enabled;
      isVideoEnabled.value = videoTrack.enabled;
      debugPrint('ğŸ“ Video toggled: ${isVideoEnabled.value}');
    }
  }

  Future<void> toggleSpeaker() async {
    isSpeakerOn.value = !isSpeakerOn.value;
    if (localStream.value != null) {
      await webrtc.Helper.setSpeakerphoneOn(isSpeakerOn.value);
      debugPrint('ğŸ“ Speaker toggled: ${isSpeakerOn.value}');
    }
  }

  Future<void> switchCamera() async {
    if (localStream.value != null) {
      final videoTrack = localStream.value!.getVideoTracks().first;
      await videoTrack.switchCamera();
      debugPrint('ğŸ“ Camera switched');
    }
  }

  void _showIncomingCallScreen(
      {required String callerId, // Display ID
      required String callerUserId, // Mongo ID
      required String callType}) {
    debugPrint(
        'ğŸ“ Showing incoming video call screen for: $callerId (User: $callerUserId)');

    // Use Get.to instead of Get.dialog for immediate display
    Get.to(
      () => VideoCallingScreen(
        contactName: callerId,
        contactPhone: callerId,
        isIncoming: true,
        callerId: callerUserId, // Pass MongoID here!
        callType: callType,
      ),
      transition: Transition.fadeIn,
      duration: const Duration(milliseconds: 100),
    );
  }

  void _showVideoCallingScreen({
    required String contactName,
    required String contactPhone,
    bool isIncoming = false,
  }) {
    debugPrint('ğŸ“ Showing video calling screen for: $contactName');

    Get.to(() => VideoCallingScreen(
          contactName: contactName,
          contactPhone: contactPhone,
          isIncoming: isIncoming,
          callType: 'video',
        ));
  }

  // video_call_service.dart mein ye changes karo:

  Future<void> _resetCallState() async {
    debugPrint('ğŸ§¹ Resetting call state...');

    currentCallerId.value = null;
    currentCalleeId.value = null;
    currentCallerUserId.value = null;
    currentCalleeUserId.value = null;
    callState.value = 'idle';
    isMuted.value = false;
    isVideoEnabled.value = true;
    isSpeakerOn.value = false;
    callType.value = 'video';
    _connectionRetryCount = 0;

    // Close peer connection first
    if (peerConnection != null) {
      try {
        await peerConnection!.close();
        debugPrint('âœ… Peer connection closed');
      } catch (e) {
        debugPrint('âš ï¸ Error closing peer connection: $e');
      }
      peerConnection = null;
    }

    // Use safe disposal method
    await _safeDisposeStreams();

    // Small delay to ensure cleanup
    await Future.delayed(const Duration(milliseconds: 200));

    debugPrint('âœ… Video call state reset completed');
  }

  @override
  void onClose() {
    _resetCallState();
    videoSocket?.dispose();
    super.onClose();
  }
}

// --- SDP Utilities ---
// Reorder m=video payloads to put VP8 first, keeping other codecs afterwards.
// Reorder m=video payloads to put VP8 first, and remove others if possible to ensure compatibility
String _preferVp8(String sdp) {
  try {
    final lines = sdp.split('\r\n');
    final videoMLineIndex = lines.indexWhere((l) => l.startsWith('m=video '));
    if (videoMLineIndex == -1) return sdp; // no video

    // Map codec name -> payload types from rtpmap
    final Map<String, List<String>> codecPts = {};
    final RegExp rtpmap = RegExp(r'^a=rtpmap:(\d+)\s+([^/]+)');
    for (final l in lines) {
      final m = rtpmap.firstMatch(l);
      if (m != null) {
        final pt = m.group(1)!;
        final name = m.group(2)!.toUpperCase();
        codecPts.putIfAbsent(name, () => []).add(pt);
      }
    }

    // Parse current m=video payload list
    final parts = lines[videoMLineIndex].split(' ');
    if (parts.length < 4) return sdp; // malformed
    final header = parts.sublist(0, 3).join(' ');
    final payloads = parts.sublist(3);

    final reordered = <String>[];
    final seen = <String>{};

    // 1. Add VP8 payloads first (Preferred for Emulator)
    final vp8Pts = codecPts['VP8'] ?? [];
    for (final pt in vp8Pts) {
      if (payloads.contains(pt) && seen.add(pt)) reordered.add(pt);
    }

    // 2. Add VP9 payloads
    final vp9Pts = codecPts['VP9'] ?? [];
    for (final pt in vp9Pts) {
      if (payloads.contains(pt) && seen.add(pt)) reordered.add(pt);
    }

    // 3. Add H264 payloads (Important fallback for Mobile)
    final h264Pts = codecPts['H264'] ?? [];
    for (final pt in h264Pts) {
      if (payloads.contains(pt) && seen.add(pt)) reordered.add(pt);
    }

    // 4. Add remaining payloads (H265, RTX, etc.)
    for (final pt in payloads) {
      if (!seen.contains(pt)) {
        reordered.add(pt);
      }
    }

    if (reordered.isEmpty) {
      debugPrint('âš ï¸ No codecs found to reorder! Keeping original.');
      return sdp;
    }

    debugPrint('ğŸ”§ Preferred Codec Order: ${reordered.join(' ')}');
    lines[videoMLineIndex] = '$header ${reordered.join(' ')}';
    return lines.join('\r\n');
  } catch (e) {
    debugPrint('âš ï¸ _preferVp8 failed: $e');
    return sdp;
  }
}
